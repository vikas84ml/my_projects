{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "final_Real_time_express_complete.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "SwLPS3bvtKD4",
        "colab_type": "code",
        "outputId": "724889fe-20c4-4e5b-a1d5-d435ad0f2be8",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 129
        }
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3Aietf%3Awg%3Aoauth%3A2.0%3Aoob&scope=email%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdocs.test%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdrive%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdrive.photos.readonly%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fpeopleapi.readonly&response_type=code\n",
            "\n",
            "Enter your authorization code:\n",
            "··········\n",
            "Mounted at /content/drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GRMLpQDDtLa-",
        "colab_type": "code",
        "outputId": "450b0d25-2b63-41f9-8bee-04f13c64b021",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "import sys, os\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense, Dropout, Activation, Flatten\n",
        "from keras.layers import Conv2D, MaxPooling2D, BatchNormalization,AveragePooling2D\n",
        "from keras.losses import categorical_crossentropy\n",
        "from keras.optimizers import Adam\n",
        "from keras.regularizers import l2\n",
        "from keras.utils import np_utils\n",
        "\n",
        "\n",
        "df=pd.read_csv('/content/drive/My Drive/fer2013.csv')\n",
        "\n",
        "X_train,train_y,X_test,test_y=[],[],[],[]\n",
        "\n",
        "for index, row in df.iterrows():\n",
        "    val=row['pixels'].split(\" \")\n",
        "    try:\n",
        "        if 'Training' in row['Usage']:\n",
        "           X_train.append(np.array(val,'float32'))\n",
        "           train_y.append(row['emotion'])\n",
        "        elif 'PublicTest' in row['Usage']:\n",
        "           X_test.append(np.array(val,'float32'))\n",
        "           test_y.append(row['emotion'])\n",
        "    except:\n",
        "        print(f\"error occured at index :{index} and row:{row}\")\n",
        "\n",
        "\n",
        "num_features = 64\n",
        "num_labels = 7\n",
        "batch_size = 64\n",
        "epochs = 30\n",
        "width, height = 48, 48\n",
        "\n",
        "\n",
        "X_train = np.array(X_train,'float32')\n",
        "train_y = np.array(train_y,'float32')\n",
        "X_test = np.array(X_test,'float32')\n",
        "test_y = np.array(test_y,'float32')\n",
        "\n",
        "train_y=np_utils.to_categorical(train_y, num_classes=num_labels)\n",
        "test_y=np_utils.to_categorical(test_y, num_classes=num_labels)\n",
        "\n",
        "#normalizing data between o and 1\n",
        "X_train -= np.mean(X_train, axis=0)\n",
        "X_train /= np.std(X_train, axis=0)\n",
        "\n",
        "X_test -= np.mean(X_test, axis=0)\n",
        "X_test /= np.std(X_test, axis=0)\n",
        "\n",
        "X_train = X_train.reshape(X_train.shape[0], 48, 48, 1)\n",
        "\n",
        "X_test = X_test.reshape(X_test.shape[0], 48, 48, 1)\n",
        "\n",
        "#1st convolution layer\n",
        "model = Sequential()\n",
        "\n",
        "model.add(Conv2D(64, kernel_size=(3, 3), activation='relu', input_shape=(X_train.shape[1:])))\n",
        "model.add(Conv2D(64,kernel_size= (3, 3), activation='relu'))\n",
        "# model.add(BatchNormalization())\n",
        "model.add(MaxPooling2D(pool_size=(2,2), strides=(2, 2)))\n",
        "model.add(Dropout(0.5))\n",
        "\n",
        "#2nd convolution layer\n",
        "model.add(Conv2D(64, (3, 3), activation='relu'))\n",
        "model.add(Conv2D(64, (3, 3), activation='relu'))\n",
        "# model.add(BatchNormalization())\n",
        "model.add(MaxPooling2D(pool_size=(2,2), strides=(2, 2)))\n",
        "model.add(Dropout(0.5))\n",
        "\n",
        "#3rd convolution layer\n",
        "model.add(Conv2D(128, (3, 3), activation='relu'))\n",
        "model.add(Conv2D(128, (3, 3), activation='relu'))\n",
        "# model.add(BatchNormalization())\n",
        "model.add(MaxPooling2D(pool_size=(2,2), strides=(2, 2)))\n",
        "\n",
        "model.add(Flatten())\n",
        "\n",
        "#fully connected neural networks\n",
        "model.add(Dense(1024, activation='relu'))\n",
        "model.add(Dropout(0.2))\n",
        "model.add(Dense(1024, activation='relu'))\n",
        "model.add(Dropout(0.2))\n",
        "\n",
        "model.add(Dense(num_labels, activation='softmax'))\n",
        "\n",
        "# model.summary()\n",
        "\n",
        "#Compliling the model\n",
        "model.compile(loss=categorical_crossentropy,\n",
        "              optimizer=Adam(),\n",
        "              metrics=['accuracy'])\n",
        "\n",
        "#Training the model\n",
        "model.fit(X_train, train_y,\n",
        "          batch_size=batch_size,\n",
        "          epochs=epochs,\n",
        "          verbose=1,\n",
        "          validation_data=(X_test, test_y),\n",
        "          shuffle=True)\n",
        "\n",
        "\n",
        "#Saving the  model to  use it later on\n",
        "fer_json = model.to_json()\n",
        "with open(\"fer2013.json\", \"w\") as json_file:\n",
        "    json_file.write(fer_json)\n",
        "model.save_weights(\"fer2013.h5\")"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Train on 28709 samples, validate on 3589 samples\n",
            "Epoch 1/30\n",
            "28709/28709 [==============================] - 23s 817us/step - loss: 1.7183 - acc: 0.2927 - val_loss: 1.5580 - val_acc: 0.3775\n",
            "Epoch 2/30\n",
            "28709/28709 [==============================] - 22s 777us/step - loss: 1.4945 - acc: 0.4129 - val_loss: 1.4131 - val_acc: 0.4478\n",
            "Epoch 3/30\n",
            "28709/28709 [==============================] - 22s 781us/step - loss: 1.3832 - acc: 0.4656 - val_loss: 1.3095 - val_acc: 0.4854\n",
            "Epoch 4/30\n",
            "28709/28709 [==============================] - 22s 777us/step - loss: 1.3235 - acc: 0.4904 - val_loss: 1.2942 - val_acc: 0.5021\n",
            "Epoch 5/30\n",
            "28709/28709 [==============================] - 22s 780us/step - loss: 1.2806 - acc: 0.5104 - val_loss: 1.2514 - val_acc: 0.5183\n",
            "Epoch 6/30\n",
            "28709/28709 [==============================] - 22s 781us/step - loss: 1.2476 - acc: 0.5252 - val_loss: 1.2354 - val_acc: 0.5224\n",
            "Epoch 7/30\n",
            "28709/28709 [==============================] - 22s 775us/step - loss: 1.2139 - acc: 0.5344 - val_loss: 1.2006 - val_acc: 0.5430\n",
            "Epoch 8/30\n",
            "28709/28709 [==============================] - 22s 779us/step - loss: 1.1897 - acc: 0.5412 - val_loss: 1.1760 - val_acc: 0.5545\n",
            "Epoch 9/30\n",
            "28709/28709 [==============================] - 22s 774us/step - loss: 1.1656 - acc: 0.5535 - val_loss: 1.1825 - val_acc: 0.5464\n",
            "Epoch 10/30\n",
            "28709/28709 [==============================] - 22s 783us/step - loss: 1.1473 - acc: 0.5617 - val_loss: 1.1763 - val_acc: 0.5517\n",
            "Epoch 11/30\n",
            "28709/28709 [==============================] - 22s 777us/step - loss: 1.1220 - acc: 0.5730 - val_loss: 1.1813 - val_acc: 0.5606\n",
            "Epoch 12/30\n",
            "28709/28709 [==============================] - 22s 776us/step - loss: 1.1125 - acc: 0.5726 - val_loss: 1.1457 - val_acc: 0.5573\n",
            "Epoch 13/30\n",
            "28709/28709 [==============================] - 22s 777us/step - loss: 1.0909 - acc: 0.5846 - val_loss: 1.1650 - val_acc: 0.5531\n",
            "Epoch 14/30\n",
            "28709/28709 [==============================] - 22s 777us/step - loss: 1.0715 - acc: 0.5915 - val_loss: 1.1324 - val_acc: 0.5667\n",
            "Epoch 15/30\n",
            "28709/28709 [==============================] - 22s 777us/step - loss: 1.0572 - acc: 0.5981 - val_loss: 1.1440 - val_acc: 0.5673\n",
            "Epoch 16/30\n",
            "28709/28709 [==============================] - 22s 775us/step - loss: 1.0419 - acc: 0.5997 - val_loss: 1.1823 - val_acc: 0.5587\n",
            "Epoch 17/30\n",
            "28709/28709 [==============================] - 22s 775us/step - loss: 1.0251 - acc: 0.6133 - val_loss: 1.1617 - val_acc: 0.5673\n",
            "Epoch 18/30\n",
            "28709/28709 [==============================] - 22s 776us/step - loss: 1.0145 - acc: 0.6105 - val_loss: 1.1551 - val_acc: 0.5659\n",
            "Epoch 19/30\n",
            "28709/28709 [==============================] - 22s 777us/step - loss: 0.9926 - acc: 0.6223 - val_loss: 1.1392 - val_acc: 0.5720\n",
            "Epoch 20/30\n",
            "28709/28709 [==============================] - 22s 780us/step - loss: 0.9854 - acc: 0.6243 - val_loss: 1.1599 - val_acc: 0.5729\n",
            "Epoch 21/30\n",
            "28709/28709 [==============================] - 22s 780us/step - loss: 0.9691 - acc: 0.6278 - val_loss: 1.1563 - val_acc: 0.5709\n",
            "Epoch 22/30\n",
            "28709/28709 [==============================] - 22s 781us/step - loss: 0.9549 - acc: 0.6357 - val_loss: 1.1662 - val_acc: 0.5798\n",
            "Epoch 23/30\n",
            "28709/28709 [==============================] - 23s 787us/step - loss: 0.9442 - acc: 0.6391 - val_loss: 1.1932 - val_acc: 0.5762\n",
            "Epoch 24/30\n",
            "28709/28709 [==============================] - 22s 783us/step - loss: 0.9288 - acc: 0.6442 - val_loss: 1.1454 - val_acc: 0.5712\n",
            "Epoch 25/30\n",
            "28709/28709 [==============================] - 23s 788us/step - loss: 0.9152 - acc: 0.6495 - val_loss: 1.1788 - val_acc: 0.5723\n",
            "Epoch 26/30\n",
            "28709/28709 [==============================] - 22s 783us/step - loss: 0.9011 - acc: 0.6568 - val_loss: 1.1531 - val_acc: 0.5804\n",
            "Epoch 27/30\n",
            "28709/28709 [==============================] - 23s 784us/step - loss: 0.8933 - acc: 0.6589 - val_loss: 1.1556 - val_acc: 0.5801\n",
            "Epoch 28/30\n",
            "28709/28709 [==============================] - 23s 786us/step - loss: 0.8799 - acc: 0.6648 - val_loss: 1.1923 - val_acc: 0.5734\n",
            "Epoch 29/30\n",
            "28709/28709 [==============================] - 23s 792us/step - loss: 0.8600 - acc: 0.6716 - val_loss: 1.2003 - val_acc: 0.5871\n",
            "Epoch 30/30\n",
            "28709/28709 [==============================] - 23s 785us/step - loss: 0.8554 - acc: 0.6772 - val_loss: 1.2203 - val_acc: 0.5740\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1uUAJG3Ctyt4",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4z47WZa-wjee",
        "colab_type": "text"
      },
      "source": [
        "# Opencv"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HJ_sv7iCwijN",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\"\"\"  \n",
        "\n",
        "import os\n",
        "import cv2\n",
        "import numpy as np\n",
        "from keras.models import model_from_json\n",
        "from keras.preprocessing import image\n",
        "\n",
        "#load model\n",
        "model = model_from_json(open(\"fer2013.json\", \"r\").read())\n",
        "#load weights\n",
        "model.load_weights('fer2013.h5')\n",
        "\n",
        "\n",
        "face_haar_cascade = cv2.CascadeClassifier('haarcascade_frontalface_default.xml')\n",
        "\n",
        "\n",
        "cap=cv2.VideoCapture(0)\n",
        "\n",
        "while True:\n",
        "    ret,test_img=cap.read()# captures frame and returns boolean value and captured image\n",
        "    if not ret:\n",
        "        continue\n",
        "    gray_img= cv2.cvtColor(test_img, cv2.COLOR_BGR2GRAY)\n",
        "\n",
        "    faces_detected = face_haar_cascade.detectMultiScale(gray_img, 1.32, 5)\n",
        "\n",
        "\n",
        "    for (x,y,w,h) in faces_detected:\n",
        "        cv2.rectangle(test_img,(x,y),(x+w,y+h),(255,0,0),thickness=7)\n",
        "        roi_gray=gray_img[y:y+w,x:x+h]#cropping region of interest i.e. face area from  image\n",
        "        roi_gray=cv2.resize(roi_gray,(48,48))\n",
        "        img_pixels = image.img_to_array(roi_gray)\n",
        "        img_pixels = np.expand_dims(img_pixels, axis = 0)\n",
        "        img_pixels /= 255\n",
        "\n",
        "        predictions = model.predict(img_pixels)\n",
        "\n",
        "        #find max indexed array\n",
        "        max_index = np.argmax(predictions[0])\n",
        "\n",
        "        emotions = ('angry', 'disgust', 'fear', 'happy', 'sad', 'surprise', 'neutral')\n",
        "        predicted_emotion = emotions[max_index]\n",
        "\n",
        "        cv2.putText(test_img, predicted_emotion, (int(x), int(y)), cv2.FONT_HERSHEY_SIMPLEX, 1, (0,0,255), 2)\n",
        "\n",
        "    resized_img = cv2.resize(test_img, (1000, 700))\n",
        "    cv2.imshow('Facial emotion analysis ',resized_img)\n",
        "\n",
        "\n",
        "\n",
        "    if cv2.waitKey(10) == ord('q'):#wait until 'q' key is pressed\n",
        "        break\n",
        "\n",
        "cap.release()\n",
        "cv2.destroyAllWindows\n",
        "\n",
        "  \"\"\""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}